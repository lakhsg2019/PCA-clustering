{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"PCA-Clustering demonstration-Questions.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"pcS8ksaymJxh","colab_type":"text"},"source":["In this demonstration we'll look at a sample example, which would be following the same procedure through which the assignment problem can be solved"]},{"cell_type":"code","metadata":{"id":"bq5y2MaKmJxn","colab_type":"code","colab":{}},"source":["#import all the necessary libraries\n","\n","import pandas as pd\n","import numpy as np\n","import pandas as pd\n","\n","# For Visualisation\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","\n","# To Scale our data\n","from sklearn.preprocessing import scale\n","\n","# To perform KMeans clustering \n","from sklearn.cluster import KMeans\n","\n","# To perform Hierarchical clustering\n","from scipy.cluster.hierarchy import linkage\n","from scipy.cluster.hierarchy import dendrogram\n","from scipy.cluster.hierarchy import cut_tree"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cT-doJbZmJxr","colab_type":"code","colab":{}},"source":["#Let's read the dataset first\n","dat = pd.read_csv('https://query.data.world/s/fgpmczptzlakpvpcuuoxrotp65hsjl')\n","dat.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z5qn69v9mJxv","colab_type":"code","colab":{}},"source":["## Let's drop species column as this is a label column and we don't need it in case of unsupervised learning models\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0im9wNMzmJxz","colab_type":"code","colab":{}},"source":["# Now, we need to create a ID columns, without this we will not be able to make necessary conclusions or we will not be able to\n","# identify that which observation goes to which cluster\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QMhdZO54mJx3","colab_type":"code","colab":{}},"source":["# Let's check the shape again\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0o6-NZpMmJx7","colab_type":"code","colab":{}},"source":["# Also, check the info again\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fB8xD8rymJx-","colab_type":"text"},"source":["## Question-1:\n","\n","Check if the data have some null values?"]},{"cell_type":"code","metadata":{"id":"YhlgA0ZXmJx_","colab_type":"code","colab":{}},"source":["# Number of nulls per column\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9OsDm86BmJyC","colab_type":"text"},"source":["### Let's begin with analysis part "]},{"cell_type":"markdown","metadata":{"id":"gvM6RUwOmJyD","colab_type":"text"},"source":["### 1. Principal Component Analysis"]},{"cell_type":"code","metadata":{"id":"sKBp3sLImJyH","colab_type":"code","colab":{}},"source":["# Let's preserve the ID column to some variable, so that we can make use of it later after perfroming PCA\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IvnY8iAbmJyK","colab_type":"code","colab":{}},"source":["# Now let's drop the ID column as it is not a predictor in our data.\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FpNeLvGImJyQ","colab_type":"code","colab":{}},"source":["# Let's check the info about the data\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f1XF4VlMmJyX","colab_type":"text"},"source":["## Question-2: \n","\n","In the below cell use standard scaler to standardise the data\n","\n","After this, check what is the maximum value in the array we have?"]},{"cell_type":"code","metadata":{"id":"7-GJxeN7mJya","colab_type":"code","colab":{}},"source":["## Let's scale the data with 4 columns\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-NnB0EhfmJyf","colab_type":"code","colab":{}},"source":["# Check maximum value here\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H16AHAtFmJyj","colab_type":"text"},"source":["## Question-3 & 4: \n","\n","Now, we will perfrom PCA on the data we have, use svd_solver as randomized and random_state as 42\n","\n","After this, check pca.components_, this will basically give you the all the vectors of the new feature space. Now check the first vector and check the first coponent of it.\n","\n","- What is the first coponent of the first vector obtained from pca.components_?\n","- What is the variance explained by the first principa component?"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"oDsRpZmymJyk","colab_type":"code","colab":{}},"source":["#Importing the PCA module\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nqGPGWxgmJyp","colab_type":"code","colab":{}},"source":["#Performing the PCA\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BO9M-E9wmJys","colab_type":"code","colab":{}},"source":["#first coponent of the first vector obtained from pca.components_\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n-HZq3t0mJyu","colab_type":"code","colab":{}},"source":["#What is the variance explained by the first principa component\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DI8u9ngsmJyx","colab_type":"code","colab":{}},"source":["#Plotting the scree plot\n","%matplotlib inline\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QecJDZcGmJy1","colab_type":"text"},"source":["## Question-5:\n","\n","Choose the correct number of PCA from the cumulative variance plot.\n","\n","What is the number of PCs we can go about?"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"VR89Re7emJy2","colab_type":"code","colab":{}},"source":["# What is the number of PCs we can go about?\n","\n","# Answer here: "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DU77h6sXmJy_","colab_type":"text"},"source":["### Run the PCA with the components choosed above"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"ojbBz-y_mJzA","colab_type":"code","colab":{}},"source":["#Finally let's go ahead and do dimenstionality reduction\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pCsu7iEfmJzK","colab_type":"code","colab":{}},"source":["# Transform the data here\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"akzvtVCTmJzO","colab_type":"code","colab":{}},"source":["# Print the resultant PCs here\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"N91PqDu7mJzS","colab_type":"code","colab":{}},"source":["#Creating a transpose so that the each column is properly arranged\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"EywBYdAqmJzU","colab_type":"code","colab":{}},"source":["# Create a dataframe with the PCs obtained\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bFdqRZVimJzY","colab_type":"code","colab":{}},"source":["# Check the head of the resultant data\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VD24etU2mJzc","colab_type":"code","colab":{}},"source":["#Let's add back the ID to the given principal components\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nbLW4tAumJzf","colab_type":"text"},"source":["### Let's perfrom Outlier treatment"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"-Hv_WL2YmJzg","colab_type":"code","colab":{}},"source":["## Let's perform Outlier Analysis\n","#Let's do the outlier analysis before proceeding to clustering\n","\n","# For PC1\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FHR8eq6pmJzi","colab_type":"code","colab":{}},"source":["# For PC2\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"iaMWgRkCmJzo","colab_type":"code","colab":{}},"source":["#Let's visualise the resultant PCs\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MBChFC71mJzu","colab_type":"text"},"source":["## Clustering "]},{"cell_type":"code","metadata":{"collapsed":true,"id":"WV7Fj4_JmJzx","colab_type":"code","colab":{}},"source":["#Calculating the Hopkins statistic\n","from sklearn.neighbors import NearestNeighbors\n","from random import sample\n","from numpy.random import uniform\n","import numpy as np\n","from math import isnan\n"," \n","def hopkins(X):\n","    d = X.shape[1]\n","    #d = len(vars) # columns\n","    n = len(X) # rows\n","    m = int(0.1 * n) \n","    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)\n"," \n","    rand_X = sample(range(0, n, 1), m)\n"," \n","    ujd = []\n","    wjd = []\n","    for j in range(0, m):\n","        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n","        ujd.append(u_dist[0][1])\n","        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)\n","        wjd.append(w_dist[0][1])\n"," \n","    H = sum(ujd) / (sum(ujd) + sum(wjd))\n","    if isnan(H):\n","        print(ujd, wjd)\n","        H = 0\n"," \n","    return H"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XajcbMuhmJz-","colab_type":"text"},"source":["## Question 6:\n","\n","Is the given data good for performing Clustering?"]},{"cell_type":"code","metadata":{"id":"PF9cfDeEmJz_","colab_type":"code","colab":{}},"source":["#Let's check the Hopkins measure\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"YOuQ_82kmJ0B","colab_type":"code","colab":{}},"source":["#Answer here: "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"DEaaZni9mJ0F","colab_type":"code","colab":{}},"source":["# Now for perfroming clustering, we need to again drop the ID column, Let's drop it\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DVslg0nUmJ0J","colab_type":"code","colab":{}},"source":["# Check the shape of the resultant data\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xoqotZykmJ0R","colab_type":"text"},"source":["### K- means Clustering"]},{"cell_type":"markdown","metadata":{"id":"itH5B80fmJ0S","colab_type":"text"},"source":["## Question-7: Look at the silhouette score plot and choose the optimal number of cluster"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"6QvpDpCXmJ0U","colab_type":"code","colab":{}},"source":["#First we'll do the silhouette score analysis\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oHAqvZV-mJ0Y","colab_type":"code","colab":{}},"source":["plt.plot(pd.DataFrame(sse_)[0], pd.DataFrame(sse_)[1]);"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xqfjqFNHmJ0c","colab_type":"text"},"source":["## Question-8: Look at the Elbow Curve plot and choose the optimal number of cluster"]},{"cell_type":"code","metadata":{"id":"axnJjp3HmJ0e","colab_type":"code","colab":{}},"source":["#Now let's proceed to the elbow curve method\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZZErSWmemJ0l","colab_type":"text"},"source":["## KMeans with the K the we have choosed"]},{"cell_type":"code","metadata":{"id":"0FL8kF78mJ0m","colab_type":"code","colab":{}},"source":["#Let's perform K means using K=\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gp9CgDCumJ0p","colab_type":"code","colab":{}},"source":["# Let's add the cluster Ids to the PCs data \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jaj4lmU4mJ0u","colab_type":"code","colab":{}},"source":["# Check the count of observation per cluster\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"IsJpcx8UmJ03","colab_type":"code","colab":{}},"source":["# Plot the Cluster with respect to the clusters obtained\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G0JuHuIFmJ1F","colab_type":"text"},"source":["## Cluster Profiling"]},{"cell_type":"code","metadata":{"id":"TBQwQhiqmJ1G","colab_type":"code","colab":{}},"source":["# Let's merge the original data with the data(ClusterID)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gil21sz6mJ1J","colab_type":"code","colab":{}},"source":["# Let's drop PCs from the data\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"l5d1xNtWmJ1T","colab_type":"text"},"source":["#### So we have performed the clustering using the PCs and have now allocated the clusterIDs back to each of the datapoints"]},{"cell_type":"markdown","metadata":{"id":"VvrdZbq0mJ1U","colab_type":"text"},"source":["## Analysis of the clusters"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"fC9WLmZgmJ1W","colab_type":"code","colab":{}},"source":["# Let's profile the cluster by taking the mean of various attributes\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"JLBGruipmJ1k","colab_type":"code","colab":{}},"source":["# Let's concat the resultant with the Cluster ID columns\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hg00GDYMmJ1o","colab_type":"code","colab":{}},"source":["# Let's add column name to it\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JvRVCgaUmJ1y","colab_type":"text"},"source":["## Finding the observations that belong to certain cluster"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"kHNCD90dmJ10","colab_type":"code","colab":{}},"source":["#Let's say my problem statement here is to just the find the flowers which have a very low petal length and petal width.\n","#Here's how you can make up for the outlier analysis that you did earlier.\n","#So you can choose those cluster means as cut offs and find the final list of flowers."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"kfenrCpGmJ15","colab_type":"code","colab":{}},"source":["#Let's use the concept of binning\n"],"execution_count":0,"outputs":[]}]}